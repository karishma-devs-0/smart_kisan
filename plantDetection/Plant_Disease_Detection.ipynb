{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Disease Detection using CNN\n",
    "**SmartKisan - Plant Disease Classification Model**\n",
    "\n",
    "This notebook trains a CNN model to classify plant diseases from leaf images.\n",
    "- **38 classes** covering diseases across multiple crops\n",
    "- Uses **Transfer Learning** with MobileNetV2 for better accuracy\n",
    "- Dataset: Plant Disease Dataset (train/valid/test splits)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/karishma-devs-0/smart_kisan/blob/main/plantDetection/Plant_Disease_Detection.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Mount Google Drive\n",
    "Upload your `Plant_Disease_Dataset` folder to Google Drive first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your dataset in Google Drive\n",
    "# Update this path to match where you uploaded the dataset\n",
    "DATASET_PATH = '/content/drive/MyDrive/Plant_Disease_Dataset'\n",
    "\n",
    "TRAIN_DIR = f'{DATASET_PATH}/train'\n",
    "VALID_DIR = f'{DATASET_PATH}/valid'\n",
    "TEST_DIR = f'{DATASET_PATH}/test/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow matplotlib seaborn scikit-learn numpy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import json\n",
    "\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "print(f'GPU available: {len(tf.config.list_physical_devices(\"GPU\")) > 0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Where to save the trained model\n",
    "MODEL_SAVE_PATH = '/content/drive/MyDrive/plant_disease_model'\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Loading & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation & test data (no augmentation, only rescaling)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_generator = val_datagen.flow_from_directory(\n",
    "    VALID_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "NUM_CLASSES = train_generator.num_classes\n",
    "CLASS_NAMES = list(train_generator.class_indices.keys())\n",
    "\n",
    "print(f'Number of classes: {NUM_CLASSES}')\n",
    "print(f'Training samples: {train_generator.samples}')\n",
    "print(f'Validation samples: {valid_generator.samples}')\n",
    "print(f'\\nClasses: {CLASS_NAMES}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from the dataset\n",
    "batch_images, batch_labels = next(train_generator)\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(15, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(batch_images[i])\n",
    "    label_idx = np.argmax(batch_labels[i])\n",
    "    ax.set_title(CLASS_NAMES[label_idx], fontsize=9)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Sample Training Images', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build the Model (Transfer Learning - MobileNetV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MobileNetV2 pretrained on ImageNet (without top classification layer)\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Freeze the base model layers initially\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build the full model\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the Model (Phase 1 - Feature Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6),\n",
    "    ModelCheckpoint(\n",
    "        f'{MODEL_SAVE_PATH}/best_model.keras',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "print('Phase 1: Training with frozen base model...')\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fine-Tune the Model (Phase 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the last 30 layers of the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with a lower learning rate\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print('Phase 2: Fine-tuning with unfrozen layers...')\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_generator,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Combine both training phases\n",
    "acc = history.history['accuracy'] + history_fine.history['accuracy']\n",
    "val_acc = history.history['val_accuracy'] + history_fine.history['val_accuracy']\n",
    "loss = history.history['loss'] + history_fine.history['loss']\n",
    "val_loss = history.history['val_loss'] + history_fine.history['val_loss']\n",
    "\n",
    "ax1.plot(acc, label='Train Accuracy')\n",
    "ax1.plot(val_acc, label='Val Accuracy')\n",
    "ax1.axvline(x=len(history.history['accuracy'])-1, color='gray', linestyle='--', label='Fine-tuning start')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(loss, label='Train Loss')\n",
    "ax2.plot(val_loss, label='Val Loss')\n",
    "ax2.axvline(x=len(history.history['loss'])-1, color='gray', linestyle='--', label='Fine-tuning start')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{MODEL_SAVE_PATH}/training_history.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "valid_generator.reset()\n",
    "predictions = model.predict(valid_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = valid_generator.classes\n",
    "\n",
    "# Classification report\n",
    "print('Classification Report:\\n')\n",
    "print(classification_report(true_classes, predicted_classes, target_names=CLASS_NAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.xticks(rotation=90, fontsize=7)\n",
    "plt.yticks(fontsize=7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{MODEL_SAVE_PATH}/confusion_matrix.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save the Model & Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "model.save(f'{MODEL_SAVE_PATH}/plant_disease_model.keras')\n",
    "\n",
    "# Save class names mapping\n",
    "class_indices = train_generator.class_indices\n",
    "# Reverse mapping: index -> class name\n",
    "index_to_class = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "with open(f'{MODEL_SAVE_PATH}/class_labels.json', 'w') as f:\n",
    "    json.dump(index_to_class, f, indent=2)\n",
    "\n",
    "print(f'Model saved to: {MODEL_SAVE_PATH}/plant_disease_model.keras')\n",
    "print(f'Class labels saved to: {MODEL_SAVE_PATH}/class_labels.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Test Prediction on a Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def predict_disease(img_path, model, class_names):\n",
    "    \"\"\"Predict plant disease from a leaf image.\"\"\"\n",
    "    img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_idx = np.argmax(prediction[0])\n",
    "    confidence = prediction[0][predicted_idx] * 100\n",
    "\n",
    "    # Get top 3 predictions\n",
    "    top3_idx = np.argsort(prediction[0])[-3:][::-1]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image.load_img(img_path))\n",
    "    plt.title(f'Prediction: {class_names[predicted_idx]}\\nConfidence: {confidence:.1f}%', fontsize=14)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    print('Top 3 Predictions:')\n",
    "    for idx in top3_idx:\n",
    "        print(f'  {class_names[idx]}: {prediction[0][idx]*100:.1f}%')\n",
    "\n",
    "    return class_names[predicted_idx], confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a sample image from the validation set\n",
    "# Change this path to test with your own images\n",
    "sample_class = CLASS_NAMES[0]\n",
    "sample_dir = os.path.join(VALID_DIR, sample_class)\n",
    "sample_img = os.path.join(sample_dir, os.listdir(sample_dir)[0])\n",
    "\n",
    "predict_disease(sample_img, model, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Upload & Test Your Own Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print('Upload a leaf image to test:')\n",
    "uploaded = files.upload()\n",
    "\n",
    "for filename in uploaded.keys():\n",
    "    print(f'\\nPredicting for: {filename}')\n",
    "    predict_disease(filename, model, CLASS_NAMES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
